{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo\n",
    "skvideo.setFFmpegPath('/Users/John/Downloads/ffmpeg-20200129-de1b2aa-macos64-static/bin')\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject on Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function act return the next action to do given the current state.\n",
    "If we are in the training, we will take a random action with probability epsilon, and we will generate an action following the current policy with probability 1 - epsilon.\n",
    "This epsilon is essential because it corresponds to the exploraton of the environment. Thanks to this epsilon, our model will be able to discover news states, sometimes with a bigger reward than ste state we already know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:,-2 :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train= 30 # set small when debugging\n",
    "epochs_test= 10 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array position defines where the agent is on the board. It has values -1 on thee extra boarders where the agent can not go, 0 where it can go and 1 on its current position. The array board defines the reward associated to every cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        return np.random.randint(4)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            \n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose - reward\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "    \n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 5.5/8.0. Average score (-2.5)\n",
      "Win/lose count 5.5/9.0. Average score (-3.0)\n",
      "Win/lose count 6.0/2.0. Average score (-0.6666666666666666)\n",
      "Win/lose count 3.5/5.0. Average score (-0.875)\n",
      "Win/lose count 7.5/9.0. Average score (-1.0)\n",
      "Win/lose count 4.5/8.0. Average score (-1.4166666666666667)\n",
      "Win/lose count 4.5/10.0. Average score (-2.0)\n",
      "Win/lose count 3.0/6.0. Average score (-2.125)\n",
      "Win/lose count 7.5/13.0. Average score (-2.5)\n",
      "Win/lose count 3.5/1.0. Average score (-2.0)\n",
      "Final score: -2.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have :\n",
    "$$$$\n",
    "$Q^{\\pi}(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a]$\n",
    "$$$$\n",
    "$= r(s,a) + E_{p^{\\pi}}[\\sum_{1\\leq t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a]$\n",
    "$$$$\n",
    "$= r(s,a) + \\gamma \\sum_{s'}p(s_1 = s',a_1 = a'|s_0 = s, a_0 = a) E_{p^{\\pi}}[\\sum_{1\\leq t\\leq T}\\gamma^{t-1}r(s_t,a_t)|s_1 = s', a_1 = a']$ (by Markov Property)\n",
    "$$$$\n",
    "$= r(s,a) + \\gamma\\sum_{s',a'}p(s',a'|s,a)E_{p^{\\pi}}[\\sum_{t' = 0}^T \\gamma^tr(s_t,a_t)|s_0 = s', a_0 = a']$ (by MDP and change of time)$$$$\n",
    "$= r(s,a) + \\gamma\\sum_{s',a'}p(s',a'|s,a)Q^{\\pi}(s',a')$ \n",
    "$= E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have :\n",
    "$$$$\n",
    "$Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a)$\n",
    "$$$$\n",
    "$= \\max_{\\pi}r(s,a) + \\gamma\\sum_{s',a'}p(s',a'|s,a)Q^{\\pi}(s',a')$\n",
    "$$$$\n",
    "$= r(s,a) + \\gamma\\sum_{s',a'}p(s',a'|s,a)\\max_{\\pi}Q^{\\pi}(s',a')$ (because propabilities are positives)\n",
    "$$$$\n",
    "$= E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is then the MSE between $Q^*(s,a)$ and $Q^{\\pi}(s,a)$ which is totaly plausible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        self.memory.append(m)\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            del self.memory[0]\n",
    "\n",
    "    def random_access(self):\n",
    "        idx = np.random.randint(0,len(self.memory))\n",
    "        return self.memory[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        tmp = self.model.predict(np.expand_dims(s,axis = 0))\n",
    "        a = np.argmax(tmp)\n",
    "        return a\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        for i in range(self.batch_size):\n",
    "            ######## FILL IN\n",
    "            s_, n_s_, a_, r_, game_over_ = self.memory.random_access()\n",
    "            input_states[i,:,:,:] = s_\n",
    "            target_q[i,:] = self.model.predict(np.expand_dims(s_,axis = 0))\n",
    "            \n",
    "            if game_over_:\n",
    "                ######## FILL IN\n",
    "                target_q[i,a_] = r_\n",
    "                \n",
    "            else:\n",
    "                ######## FILL IN\n",
    "                target_q[i,a_] = r_ + self.discount * np.max(self.model.predict(np.expand_dims(n_s_,axis = 0)))\n",
    "        ######## FILL IN\n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        \n",
    "        ####### FILL IN\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=(5,5,self.n_state)))\n",
    "        model.add(Dense(100))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(30))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(4))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        model.summary()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 124       \n",
      "=================================================================\n",
      "Total params: 8,254\n",
      "Trainable params: 8,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 000/030 | Loss 0.0151 | Win/lose count 4.0/5.0 (-1.0)\n",
      "Epoch 001/030 | Loss 0.0034 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 002/030 | Loss 0.0022 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 003/030 | Loss 0.0078 | Win/lose count 5.5/2.0 (3.5)\n",
      "Epoch 004/030 | Loss 0.0014 | Win/lose count 2.0/3.0 (-1.0)\n",
      "Epoch 005/030 | Loss 0.0020 | Win/lose count 2.5/3.0 (-0.5)\n",
      "Epoch 006/030 | Loss 0.0036 | Win/lose count 2.5/3.0 (-0.5)\n",
      "Epoch 007/030 | Loss 0.0434 | Win/lose count 2.0/4.0 (-2.0)\n",
      "Epoch 008/030 | Loss 0.0037 | Win/lose count 2.0/5.0 (-3.0)\n",
      "Epoch 009/030 | Loss 0.0058 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 010/030 | Loss 0.0069 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 011/030 | Loss 0.0059 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 012/030 | Loss 0.0084 | Win/lose count 4.5/5.0 (-0.5)\n",
      "Epoch 013/030 | Loss 0.0057 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 014/030 | Loss 0.0129 | Win/lose count 5.0/1.0 (4.0)\n",
      "Epoch 015/030 | Loss 0.0023 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 016/030 | Loss 0.0023 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 017/030 | Loss 0.0023 | Win/lose count 6.5/2.0 (4.5)\n",
      "Epoch 018/030 | Loss 0.0032 | Win/lose count 3.5/6.0 (-2.5)\n",
      "Epoch 019/030 | Loss 0.0010 | Win/lose count 4.0/1.0 (3.0)\n",
      "Epoch 020/030 | Loss 0.0042 | Win/lose count 3.5/0 (3.5)\n",
      "Epoch 021/030 | Loss 0.0014 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 022/030 | Loss 0.0597 | Win/lose count 3.0/3.0 (0.0)\n",
      "Epoch 023/030 | Loss 0.0642 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 024/030 | Loss 0.0059 | Win/lose count 5.0/5.0 (0.0)\n",
      "Epoch 025/030 | Loss 0.0060 | Win/lose count 0/2.0 (-2.0)\n",
      "Epoch 026/030 | Loss 0.0021 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 027/030 | Loss 0.0479 | Win/lose count 7.0/5.0 (2.0)\n",
      "Epoch 028/030 | Loss 0.0056 | Win/lose count 7.0/2.0 (5.0)\n",
      "Epoch 029/030 | Loss 0.0332 | Win/lose count 6.5/1.0 (5.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, epochs_train, prefix='fc_train')\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        ###### FILL IN\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters=30,kernel_size=3,input_shape=(5,5,self.n_state)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(filters=20,kernel_size=3))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4))\n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 30)          570       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3, 3, 30)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 20)          5420      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1, 1, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 6,074\n",
      "Trainable params: 6,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 000/030 | Loss 0.0035 | Win/lose count 4.0/5.0 (-1.0)\n",
      "Epoch 001/030 | Loss 0.0133 | Win/lose count 4.5/5.0 (-0.5)\n",
      "Epoch 002/030 | Loss 0.0059 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 003/030 | Loss 0.0028 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 004/030 | Loss 0.0046 | Win/lose count 4.5/5.0 (-0.5)\n",
      "Epoch 005/030 | Loss 0.0043 | Win/lose count 3.0/3.0 (0.0)\n",
      "Epoch 006/030 | Loss 0.0074 | Win/lose count 5.0/1.0 (4.0)\n",
      "Epoch 007/030 | Loss 0.0012 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 008/030 | Loss 0.0044 | Win/lose count 8.0/3.0 (5.0)\n",
      "Epoch 009/030 | Loss 0.0011 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 010/030 | Loss 0.0085 | Win/lose count 7.5/2.0 (5.5)\n",
      "Epoch 011/030 | Loss 0.0543 | Win/lose count 7.0/2.0 (5.0)\n",
      "Epoch 012/030 | Loss 0.0023 | Win/lose count 6.0/1.0 (5.0)\n",
      "Epoch 013/030 | Loss 0.0012 | Win/lose count 11.5/3.0 (8.5)\n",
      "Epoch 014/030 | Loss 0.0549 | Win/lose count 9.5/3.0 (6.5)\n",
      "Epoch 015/030 | Loss 0.0035 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 016/030 | Loss 0.0044 | Win/lose count 13.0/3.0 (10.0)\n",
      "Epoch 017/030 | Loss 0.0067 | Win/lose count 12.5/2.0 (10.5)\n",
      "Epoch 018/030 | Loss 0.0034 | Win/lose count 10.0/3.0 (7.0)\n",
      "Epoch 019/030 | Loss 0.0036 | Win/lose count 11.5/4.0 (7.5)\n",
      "Epoch 020/030 | Loss 0.0028 | Win/lose count 9.5/2.0 (7.5)\n",
      "Epoch 021/030 | Loss 0.0034 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 022/030 | Loss 0.0028 | Win/lose count 13.0/5.0 (8.0)\n",
      "Epoch 023/030 | Loss 0.0485 | Win/lose count 9.0/1.0 (8.0)\n",
      "Epoch 024/030 | Loss 0.0021 | Win/lose count 7.5/4.0 (3.5)\n",
      "Epoch 025/030 | Loss 0.0491 | Win/lose count 8.0/4.0 (4.0)\n",
      "Epoch 026/030 | Loss 0.0015 | Win/lose count 14.5/2.0 (12.5)\n",
      "Epoch 027/030 | Loss 0.0027 | Win/lose count 17.5/4.0 (13.5)\n",
      "Epoch 028/030 | Loss 0.0035 | Win/lose count 9.0/2.0 (7.0)\n",
      "Epoch 029/030 | Loss 0.0497 | Win/lose count 12.0/1.0 (11.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent,env,epochs_train,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 3, 3, 30)          570       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 3, 3, 30)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 1, 1, 20)          5420      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1, 1, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 6,074\n",
      "Trainable params: 6,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_16 (Flatten)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 124       \n",
      "=================================================================\n",
      "Total params: 8,254\n",
      "Trainable params: 8,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test of the CNN\n",
      "Win/lose count 10.0/0. Average score (10.0)\n",
      "Win/lose count 11.5/3.0. Average score (9.25)\n",
      "Win/lose count 7.0/1.0. Average score (8.166666666666666)\n",
      "Win/lose count 12.0/1.0. Average score (8.875)\n",
      "Win/lose count 8.5/3.0. Average score (8.2)\n",
      "Win/lose count 15.5/3.0. Average score (8.916666666666666)\n",
      "Win/lose count 10.5/0. Average score (9.142857142857142)\n",
      "Win/lose count 16.5/1.0. Average score (9.9375)\n",
      "Win/lose count 11.0/0. Average score (10.055555555555555)\n",
      "Win/lose count 15.5/0. Average score (10.6)\n",
      "Final score: 10.6\n",
      "Test of the FC\n",
      "Win/lose count 10.0/1.0. Average score (9.0)\n",
      "Win/lose count 6.0/0. Average score (7.5)\n",
      "Win/lose count 4.5/0. Average score (6.5)\n",
      "Win/lose count 6.0/1.0. Average score (6.125)\n",
      "Win/lose count 8.5/1.0. Average score (6.4)\n",
      "Win/lose count 11.0/3.0. Average score (6.666666666666667)\n",
      "Win/lose count 6.5/1.0. Average score (6.5)\n",
      "Win/lose count 4.5/1.0. Average score (6.125)\n",
      "Win/lose count 4.5/3.0. Average score (5.611111111111111)\n",
      "Win/lose count 14.0/5.0. Average score (5.95)\n",
      "Final score: 5.95\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.9)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temperature : 0.9 , CNN score 10.6 and FC score 5.95 \n",
    "\n",
    "temperature : 0.7 , CNN score 6.7 and FC score 2.7  \n",
    "\n",
    "temperature : 0.3 , CNN score 1.9 and FC score -1.95 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test9.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test9.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,decay_parameter_epsilon=0.3,prefix=''):\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        agent.set_epsilon(agent.epsilon*(1-decay_parameter_epsilon))\n",
    "        while not game_over:\n",
    "            action = agent.act(state)\n",
    "\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action, train=True)\n",
    "\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        \n",
    "class EnvironmentExploring(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size))\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action,train=False):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1     \n",
    "\n",
    "        reward = 0\n",
    "        if train:\n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] = 0.1\n",
    "\n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:,-2:] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 3, 3, 30)          840       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 3, 3, 30)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 1, 1, 20)          5420      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 1, 1, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 6,344\n",
      "Trainable params: 6,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 000/030 | Loss 0.0212 | Win/lose count 5.0/27.8000000000001 (-22.8000000000001)\n",
      "Epoch 001/030 | Loss 0.0147 | Win/lose count 11.0/26.600000000000076 (-15.600000000000076)\n",
      "Epoch 002/030 | Loss 0.0074 | Win/lose count 9.0/23.30000000000003 (-14.30000000000003)\n",
      "Epoch 003/030 | Loss 0.0102 | Win/lose count 16.0/18.5 (-2.5)\n",
      "Epoch 004/030 | Loss 0.0142 | Win/lose count 8.0/18.299999999999997 (-10.299999999999997)\n",
      "Epoch 005/030 | Loss 0.0154 | Win/lose count 12.5/18.800000000000004 (-6.300000000000004)\n",
      "Epoch 006/030 | Loss 0.0086 | Win/lose count 6.0/21.20000000000002 (-15.20000000000002)\n",
      "Epoch 007/030 | Loss 0.0250 | Win/lose count 3.0/19.600000000000012 (-16.600000000000012)\n",
      "Epoch 008/030 | Loss 0.0079 | Win/lose count 4.5/17.899999999999984 (-13.399999999999984)\n",
      "Epoch 009/030 | Loss 0.0052 | Win/lose count 8.0/18.799999999999983 (-10.799999999999983)\n",
      "Epoch 010/030 | Loss 0.0047 | Win/lose count 8.0/18.199999999999992 (-10.199999999999992)\n",
      "Epoch 011/030 | Loss 0.0275 | Win/lose count 11.5/15.399999999999961 (-3.8999999999999613)\n",
      "Epoch 012/030 | Loss 0.0360 | Win/lose count 19.0/14.09999999999997 (4.9000000000000306)\n",
      "Epoch 013/030 | Loss 0.0091 | Win/lose count 22.5/13.399999999999968 (9.100000000000032)\n",
      "Epoch 014/030 | Loss 0.0046 | Win/lose count 15.5/14.499999999999964 (1.0000000000000355)\n",
      "Epoch 015/030 | Loss 0.0078 | Win/lose count 9.5/15.89999999999996 (-6.3999999999999595)\n",
      "Epoch 016/030 | Loss 0.0126 | Win/lose count 15.0/14.999999999999963 (3.730349362740526e-14)\n",
      "Epoch 017/030 | Loss 0.0041 | Win/lose count 13.0/14.999999999999963 (-1.9999999999999627)\n",
      "Epoch 018/030 | Loss 0.0416 | Win/lose count 11.5/14.999999999999963 (-3.4999999999999627)\n",
      "Epoch 019/030 | Loss 0.0131 | Win/lose count 12.5/15.59999999999996 (-3.0999999999999606)\n",
      "Epoch 020/030 | Loss 0.0078 | Win/lose count 17.5/13.299999999999969 (4.200000000000031)\n",
      "Epoch 021/030 | Loss 0.0160 | Win/lose count 13.5/14.399999999999965 (-0.8999999999999648)\n",
      "Epoch 022/030 | Loss 0.0085 | Win/lose count 9.0/17.399999999999977 (-8.399999999999977)\n",
      "Epoch 023/030 | Loss 0.0163 | Win/lose count 19.0/12.89999999999997 (6.10000000000003)\n",
      "Epoch 024/030 | Loss 0.0080 | Win/lose count 8.5/16.79999999999997 (-8.299999999999969)\n",
      "Epoch 025/030 | Loss 0.0078 | Win/lose count 16.0/13.09999999999997 (2.9000000000000306)\n",
      "Epoch 026/030 | Loss 0.0084 | Win/lose count 23.0/11.699999999999974 (11.300000000000026)\n",
      "Epoch 027/030 | Loss 0.0085 | Win/lose count 10.5/16.29999999999996 (-5.799999999999962)\n",
      "Epoch 028/030 | Loss 0.0064 | Win/lose count 20.0/12.499999999999972 (7.500000000000028)\n",
      "Epoch 029/030 | Loss 0.0057 | Win/lose count 16.0/14.599999999999964 (1.4000000000000359)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.6, memory_size=2000, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 20.0/1.0. Average score (19.0)\n",
      "Win/lose count 15.0/0. Average score (17.0)\n",
      "Win/lose count 17.0/1.0. Average score (16.666666666666668)\n",
      "Win/lose count 18.0/1.0. Average score (16.75)\n",
      "Win/lose count 0.5/0. Average score (13.5)\n",
      "Win/lose count 23.0/0. Average score (15.083333333333334)\n",
      "Win/lose count 7.5/0. Average score (14.0)\n",
      "Win/lose count 17.0/0. Average score (14.375)\n",
      "Win/lose count 23.5/0. Average score (15.38888888888889)\n",
      "Win/lose count 5.0/0. Average score (14.35)\n",
      "Final score: 14.35\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
    "#HTML(display_videos('cnn_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
